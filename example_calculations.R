### 1. Accumulate AFM data  ####
# Example of calculations to obtain the best and average metrics from AlphaFold output and combining metrics as measures for interaction. 
# example_data_1.csv and example_data_2.csv have been generated by extracting the confidence metrics from the raw predictions.


library(data.table)

# load data into datatable
raw_AFM_dt <- fread("/data/gpfs/projects/punim1869/users/lreber/workspace/publications_scripts/example_data_1.csv")

#calculate the model confidence and pDockQ2 value
raw_AFM_dt[, `AFM model confidence` := 0.2*`AFM pTM` + 0.8*`AFM ipTM`]
raw_AFM_dt[, `AFM pDockQ2` := (`AFM pDockQ2_A` +`AFM pDockQ2_A`)/2]

#remove pDockQ2_A and pDockQ2_B as not needed anymore
raw_AFM_dt <- raw_AFM_dt[,-c(7,8)]


#get the metrics of the best model determined based on the ranking
metric_AFM_best <- raw_AFM_dt[`AFM rank` =="rank_001"]
#remove rank column as not needed
metric_AFM_best <- metric_AFM_best[,-c(4)]
#change colnames to indicate that these are best values
colnames(metric_AFM_best) <- c("Protein_Pair","sequence_protein_A","sequence_protein_B", "best pTM AFM", "best AFM ipTM","best AFM pDockQ","best AFM LIS","best AFM model confidence","best AFM pDockQ2")

#calculate average across the five models
cols_to_summarize <- c("AFM pTM", "AFM ipTM","AFM pDockQ", "AFM LIS", "AFM model confidence", "AFM pDockQ2")
metric_AFM_average <- raw_AFM_dt[, lapply(.SD, function(x) list(mean = mean(x, na.rm = TRUE))), by = Protein_Pair, .SDcols = cols_to_summarize]
metric_AFM_average[, (cols_to_summarize) := lapply(.SD, as.numeric), .SDcols = cols_to_summarize]
#change colnames to indicate that these are average values
colnames(metric_AFM_average) <- c("Protein_Pair", "average pTM AFM", "average AFM ipTM","average AFM pDockQ","average AFM LIS","average AFM model confidence","average AFM pDockQ2")


# make one datatable with best and average metrics
accumulated_AFM_dt <- merge(metric_AFM_best,metric_AFM_average,by="Protein_Pair")


### 2. Add AF3 data  ####
raw_AF3_dt <- fread("/data/gpfs/projects/punim1869/users/lreber/workspace/publications_scripts/example_data_2.csv")

#change naming that is based on ALphafold3 outputs
raw_AF3_dt$Protein_Pair <- toupper(raw_AF3_dt$Protein_Pair)
raw_AF3_dt[, Protein_Pair := tstrsplit(Protein_Pair, "FOLD_", fixed=TRUE)[2]]

#calculate model confidence
raw_AF3_dt[, `AF3 model confidence` := 0.2*`AF3 pTM` + 0.8*`AF3 ipTM`]



#get the metrics of the best model deterimed based on the ranking
metric_AF3_best <- raw_AF3_dt[`AF3 rank` =="0"]
#remove rank column as not needed
metric_AF3_best <- metric_AF3_best[,-c(2)]
#change colnames to indicate that these are best values
colnames(metric_AF3_best) <- c("Protein_Pair","best AF3 pTM", "best AF3 ipTM","best AF3 LIS","best AF3 model confidence")


#calculate average across the five models
cols_to_summarize <- c("AF3 pTM", "AF3 ipTM","AF3 LIS","AF3 model confidence")
metric_AF3_average <- raw_AF3_dt[, lapply(.SD, function(x) list(mean = mean(x, na.rm = TRUE))), by = Protein_Pair, .SDcols = cols_to_summarize]
metric_AF3_average[, (cols_to_summarize) := lapply(.SD, as.numeric), .SDcols = cols_to_summarize]
#change colnames to indicate that these are average values
colnames(metric_AF3_average) <- c("Protein_Pair", "average AF3 pTM", "average AF3 ipTM","average AF3 LIS","average AF3 model confidence")

# make one datatable with best and average metrics
accumulated_AF3_dt <- merge(metric_AF3_best,metric_AF3_average,by="Protein_Pair")



# make the Protein pair ids the same format for merging AFM and AF3 data
accumulated_AFM_dt$Protein_Pair <- toupper(accumulated_AFM_dt$Protein_Pair) 

merged_AFM_AF3_dt <- merge(accumulated_AFM_dt, accumulated_AF3_dt, by = "Protein_Pair", all.x = TRUE)




###Calculate combined metrics####
merged_AFM_AF3_dt[, `Mean AFM score` := (`average AFM ipTM` + `average AFM LIS`)/2]
merged_AFM_AF3_dt[, `AFM & AF3 score` := (`average AFM ipTM` + `average AFM LIS` + `best AF3 ipTM`)/3]

